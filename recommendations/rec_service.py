import logging
import pathlib
import pickle
import shutil
import asyncio
import grpc
from typing import Tuple, Optional, List, Dict, Any, Union
from threading import RLock

import pandas as pd
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger
import pytz

import warnings
from lightfm import LightFM
from pandas import DataFrame
from rectools import Columns
from rectools.dataset import Dataset, Interactions
from rectools.model_selection import TimeRangeSplitter
from rectools.models import LightFMWrapperModel, load_model
from rectools.models.base import ModelBase

from recommendations.data_preparer import DataPrepareService, BlacklistManager
from recommendations.config import MODEL_CONFIG

warnings.filterwarnings('ignore')
logger = logging.getLogger(__name__)


class ModelStorage:
    """
    –ö–ª–∞—Å—Å –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –º–æ–¥–µ–ª–µ–π –∏ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –Ω–∞ –¥–∏—Å–∫–µ.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≤–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –æ—Ç–∫–∞—Ç.
    """
    def __init__(self, model_dir: str = "data"):
        self.model_dir = pathlib.Path(model_dir)
        self.current_dir = self.model_dir / "cur"
        self.prev_dir = self.model_dir / "prev"
        self.file_lock = asyncio.Lock()
        
        # –°–æ–∑–¥–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        self.current_dir.mkdir(parents=True, exist_ok=True)
        self.prev_dir.mkdir(parents=True, exist_ok=True)
    
    @property
    def current_model_path(self) -> pathlib.Path:
        return self.current_dir / "model.pkl"
    
    @property
    def current_dataset_path(self) -> pathlib.Path:
        return self.current_dir / "dataset.pkl"
    
    async def save_model(self, model: ModelBase, dataset: Optional[Dataset] = None) -> bool:
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–æ–¥–µ–ª—å –∏ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –¥–∞—Ç–∞—Å–µ—Ç –Ω–∞ –¥–∏—Å–∫ —Å –≤–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º.
        
        Args:
            model: –ú–æ–¥–µ–ª—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            dataset: –î–∞—Ç–∞—Å–µ—Ç –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            
        Returns:
            bool: –£—Å–ø–µ—à–Ω–æ –ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
        """
        async with self.file_lock:
            try:
                # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—É—Ç–∏ –¥–ª—è –∞—Ç–æ–º–∞—Ä–Ω–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
                tmp_model_path = self.current_model_path.with_suffix(".tmp")
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
                model.save(str(tmp_model_path))
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞—Ç–∞—Å–µ—Ç, –µ—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω
                if dataset is not None:
                    tmp_dataset_path = self.current_dataset_path.with_suffix(".tmp")
                    with open(tmp_dataset_path, 'wb') as dataset_file:
                        pickle.dump(dataset, dataset_file)
                
                # –ë—ç–∫–∞–ø —Ç–µ–∫—É—â–∏—Ö —Ñ–∞–π–ª–æ–≤
                if self.current_model_path.exists():
                    shutil.move(str(self.current_model_path), str(self.prev_dir / "model.pkl"))
                    
                    if dataset is not None and self.current_dataset_path.exists():
                        shutil.move(str(self.current_dataset_path), str(self.prev_dir / "dataset.pkl"))
                
                # –ê—Ç–æ–º–∞—Ä–Ω–æ–µ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ
                tmp_model_path.replace(self.current_model_path)
                if dataset is not None:
                    tmp_dataset_path.replace(self.current_dataset_path)
                
                logger.info(f"–ú–æ–¥–µ–ª—å –∏ –¥–∞—Ç–∞—Å–µ—Ç —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã")
                return True
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏: {e}")
                return False
    
    async def load_model(self) -> Tuple[Optional[ModelBase], Optional[Dataset]]:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å –∏ –¥–∞—Ç–∞—Å–µ—Ç —Å –¥–∏—Å–∫–∞.
        
        Returns:
            Tuple[Optional[ModelBase], Optional[Dataset]]: –ó–∞–≥—Ä—É–∂–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –∏ –¥–∞—Ç–∞—Å–µ—Ç –∏–ª–∏ None
        """
        try:
            if not self.current_model_path.exists() or not self.current_dataset_path.exists():
                logger.warning("–ú–æ–¥–µ–ª—å –∏–ª–∏ –¥–∞—Ç–∞—Å–µ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –Ω–∞ –¥–∏—Å–∫–µ")
                return None, None
                
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç
            with open(self.current_dataset_path, 'rb') as f:
                dataset = pickle.load(f)
                
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
            model = load_model(f=str(self.current_model_path))
            
            logger.info("–ú–æ–¥–µ–ª—å –∏ –¥–∞—Ç–∞—Å–µ—Ç —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
            return model, dataset
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            return None, None
    
    async def rollback(self) -> Tuple[Optional[ModelBase], Optional[Dataset]]:
        """
        –û—Ç–∫–∞—Ç—ã–≤–∞–µ—Ç –º–æ–¥–µ–ª—å –∏ –¥–∞—Ç–∞—Å–µ—Ç –∫ –ø—Ä–µ–¥—ã–¥—É—â–µ–π –≤–µ—Ä—Å–∏–∏.
        
        Returns:
            Tuple[Optional[ModelBase], Optional[Dataset]]: –ü—Ä–µ–¥—ã–¥—É—â–∞—è –º–æ–¥–µ–ª—å –∏ –¥–∞—Ç–∞—Å–µ—Ç –∏–ª–∏ None
        """
        async with self.file_lock:
            try:
                prev_model_path = self.prev_dir / "model.pkl"
                prev_dataset_path = self.prev_dir / "dataset.pkl"
                
                if not prev_model_path.exists() or not prev_dataset_path.exists():
                    logger.warning("–ü—Ä–µ–¥—ã–¥—É—â–∏–µ –≤–µ—Ä—Å–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –¥–ª—è –æ—Ç–∫–∞—Ç–∞")
                    return None, None
                
                # –í—Ä–µ–º–µ–Ω–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â–∏–µ —Ñ–∞–π–ª—ã
                if self.current_model_path.exists():
                    shutil.move(str(self.current_model_path), str(self.current_dir / "model.bak"))
                    shutil.move(str(self.current_dataset_path), str(self.current_dir / "dataset.bak"))
                
                # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –≤–µ—Ä—Å–∏–∏
                shutil.move(str(prev_model_path), str(self.current_model_path))
                shutil.move(str(prev_dataset_path), str(self.current_dataset_path))
                
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ—Ç–∫–∞—á–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
                return await self.load_model()
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–∫–∞—Ç–∞ –º–æ–¥–µ–ª–∏: {e}")
                return None, None


class ModelManager:
    """
    –°–∏–Ω–≥–ª—Ç–æ–Ω –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –º–æ–¥–µ–ª—å—é —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π.
    –û—Ç–≤–µ—á–∞–µ—Ç –∑–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é, –æ–±—É—á–µ–Ω–∏–µ –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π.
    """
    _instance = None
    _model: Optional[ModelBase] = None
    _dataset: Optional[Dataset] = None
    _version = 0
    _rw_lock = RLock()
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._storage = ModelStorage()
        return cls._instance
    
    async def initialize(self):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –º–µ–Ω–µ–¥–∂–µ—Ä –º–æ–¥–µ–ª–µ–π.
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –º–æ–¥–µ–ª—å —Å –¥–∏—Å–∫–∞ –∏–ª–∏ –æ–±—É—á–∞–µ—Ç –Ω–æ–≤—É—é.
        """
        model, dataset = await self._storage.load_model()
        
        if model is not None and dataset is not None:
            if model.is_fitted:
                with self._rw_lock:
                    self._model = model
                    self._dataset = dataset
                    self._version += 1
                logger.info(f"–ú–æ–¥–µ–ª—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞, –≤–µ—Ä—Å–∏—è {self._version}")
            else:
                logger.warning("–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞! –ù–∞—á–∏–Ω–∞–µ–º –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ...")
                await self.train()
        else:
            logger.warning("–ú–æ–¥–µ–ª—å –∏–ª–∏ –¥–∞—Ç–∞—Å–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç. –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ...")
            await self.train()

    async def fit_partial(self, new_interactions: DataFrame = None, new_user_features: DataFrame = None) -> bool:
        """
        –ß–∞—Å—Ç–∏—á–Ω–æ–µ –¥–æ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
        
        Args:
            new_interactions: –ù–æ–≤—ã–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è
            new_user_features: –ù–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
            
        Returns:
            bool: –£—Å–ø–µ—à–Ω–æ –ª–∏ –¥–æ–æ–±—É—á–µ–Ω–∏–µ
        """
        with self._rw_lock:
            if self._model is None or not self._model.is_fitted:
                logger.warning("–ú–æ–¥–µ–ª—å –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –∏–ª–∏ –Ω–µ –æ–±—É—á–µ–Ω–∞ –¥–ª—è —á–∞—Å—Ç–∏—á–Ω–æ–≥–æ –¥–æ–æ–±—É—á–µ–Ω–∏—è")
                return False
                
            try:
                # –õ–æ–≥–∏–∫–∞ –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏
                # –ó–¥–µ—Å—å –º—ã –ø—Ä–æ—Å—Ç–æ –æ–±–Ω–æ–≤–ª—è–µ–º —Ç–µ–∫—É—â—É—é –º–æ–¥–µ–ª—å
                logger.info(f"–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è —á–∞—Å—Ç–∏—á–Ω–æ–µ –¥–æ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ {len(new_interactions)} –∑–∞–ø–∏—Å—è—Ö")
                
                # –í —Ä–µ–∞–ª—å–Ω–æ–π –∏–º–ø–ª–µ–º–µ–Ω—Ç–∞—Ü–∏–∏ –∑–¥–µ—Å—å –±—ã –±—ã–ª –∫–æ–¥ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –∏ –¥–∞—Ç–∞—Å–µ—Ç–∞
                # model.fit_partial(new_interactions, new_user_features)
                
                await self._storage.save_model(self._model, self._dataset)
                self._version += 1
                return True
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ —á–∞—Å—Ç–∏—á–Ω–æ–≥–æ –¥–æ–æ–±—É—á–µ–Ω–∏—è: {e}")
                return False

    async def train(self) -> bool:
        """
        –ü–æ–ª–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö.
        
        Returns:
            bool: –£—Å–ø–µ—à–Ω–æ –ª–∏ –æ–±—É—á–µ–Ω–∏–µ
        """
        try:
            # –û–±–Ω–æ–≤–ª—è–µ–º —á–µ—Ä–Ω—ã–π —Å–ø–∏—Å–æ–∫
            await BlacklistManager.refresh_blacklist()
            
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            user_features = await DataPrepareService.get_users_features()
            items_features = await DataPrepareService.get_titles_features()
            interactions = await DataPrepareService.get_interactions()
            
            if interactions.empty:
                logger.error("–î–∞–Ω–Ω—ã–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π –ø—É—Å—Ç—ã. –û–±—É—á–µ–Ω–∏–µ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ.")
                return False
            
            # –ö–æ–Ω—Å—Ç—Ä—É–∏—Ä—É–µ–º –¥–∞—Ç–∞—Å–µ—Ç
            dataset = Dataset.construct(
                interactions_df=interactions,
                user_features_df=user_features,
                cat_user_features=["age_group", "sex", "preference"],
                item_features_df=items_features,
                cat_item_features=["type_id", "genres", "categories", "count_chapters", "age_limit", "relation_list"],
            )
            
            # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
            lightfm_model = LightFM(
                no_components=MODEL_CONFIG.get("no_components", 100),
                loss=MODEL_CONFIG.get("loss", "bpr"),
                random_state=MODEL_CONFIG.get("random_state", 60)
            )
            
            model = LightFMWrapperModel(
                lightfm_model,
                num_threads=MODEL_CONFIG.get("num_threads", 3),
                epochs=MODEL_CONFIG.get("epochs", 30)
            )
            
            # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
            logger.info("–ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
            model.fit(dataset)
            
            if not model.is_fitted:
                logger.error("–û—à–∏–±–∫–∞! –ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–∏–ª–∞—Å—å!")
                return False
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –º–æ–¥–µ–ª—å –≤ –ø–∞–º—è—Ç–∏ –∏ –Ω–∞ –¥–∏—Å–∫–µ
            with self._rw_lock:
                self._model = model
                self._dataset = dataset
                
            await self._storage.save_model(model, dataset)
            self._version += 1
            
            logger.info(f"–ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞, –≤–µ—Ä—Å–∏—è {self._version}")
            return True
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏: {str(e)}")
            return False

    async def get_model(self) -> Tuple[ModelBase, Dataset]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—É—â—É—é –º–æ–¥–µ–ª—å –∏ –¥–∞—Ç–∞—Å–µ—Ç.
        
        Returns:
            Tuple[ModelBase, Dataset]: –¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å –∏ –¥–∞—Ç–∞—Å–µ—Ç
        
        Raises:
            ValueError: –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞
        """
        with self._rw_lock:
            if self._model is None or self._dataset is None:
                raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
            return self._model, self._dataset

    @property
    def current_version(self) -> int:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—É—â—É—é –≤–µ—Ä—Å–∏—é –º–æ–¥–µ–ª–∏.
        
        Returns:
            int: –¢–µ–∫—É—â–∞—è –≤–µ—Ä—Å–∏—è –º–æ–¥–µ–ª–∏
        """
        return self._version

    @property
    def model(self) -> Optional[ModelBase]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—É—â—É—é –º–æ–¥–µ–ª—å.
        
        Returns:
            Optional[ModelBase]: –¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å –∏–ª–∏ None
        """
        return self._model


class RecService:
    """
    –°–µ—Ä–≤–∏—Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—é—â–∏–π API –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
    –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –º–æ–¥–µ–ª—è–º–∏.
    """
    _scheduler: Optional[AsyncIOScheduler] = None

    @classmethod
    def start_scheduler(cls):
        """
        –ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –¥–ª—è –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏.
        """
        if cls._scheduler is None:
            cls._scheduler = AsyncIOScheduler(timezone=pytz.timezone("Europe/Moscow"))
            cls._scheduler.add_job(
                cls._scheduled_train, 
                trigger=CronTrigger(hour=4, minute=0), 
                max_instances=1
            )
            cls._scheduler.start()
            logger.info("‚úÖ –ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –∑–∞–ø—É—â–µ–Ω")

    @staticmethod
    async def _handle_request(context: grpc.ServicerContext) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞.
        
        Args:
            context: gRPC –∫–æ–Ω—Ç–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞
            
        Returns:
            bool: –ì–æ—Ç–æ–≤–∞ –ª–∏ –º–æ–¥–µ–ª—å –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞
        """
        try:
            if ModelManager().model is None:
                await context.abort(grpc.StatusCode.FAILED_PRECONDITION, "‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
                return False
            return True
        except Exception as e:
            logger.error(f"üî• –í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞: {str(e)}")
            await context.abort(grpc.StatusCode.INTERNAL, f"–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞: {str(e)}")
            return False

    @staticmethod
    async def rec(user_id: int, context: Optional[grpc.ServicerContext] = None) -> List[int]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
        
        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            context: gRPC –∫–æ–Ω—Ç–µ–∫—Å—Ç (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            
        Returns:
            List[int]: –°–ø–∏—Å–æ–∫ ID —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–π
            
        Raises:
            Exception: –ü—Ä–∏ –æ—à–∏–±–∫–µ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        """
        if context and not await RecService._handle_request(context):
            return []
            
        try:
            model, dataset = await ModelManager().get_model()
            recos = model.recommend(users=[user_id], dataset=dataset, k=40, filter_viewed=True)
            return recos['item_id'].tolist()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {e}")
            if context:
                await context.abort(grpc.StatusCode.INTERNAL, str(e))
            raise

    @classmethod
    async def _scheduled_train(cls):
        """
        –ó–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏.
        """
        logger.info("–ù–∞—á–∏–Ω–∞–µ–º –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
        await ModelManager().train()

    @staticmethod
    async def relevant(item_id: int, context: Optional[grpc.ServicerContext] = None) -> List[int]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –ø–æ—Ö–æ–∂–∏–µ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è.
        
        Args:
            item_id: ID –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è
            context: gRPC –∫–æ–Ω—Ç–µ–∫—Å—Ç (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            
        Returns:
            List[int]: –°–ø–∏—Å–æ–∫ ID –ø–æ—Ö–æ–∂–∏—Ö –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–π
            
        Raises:
            Exception: –ü—Ä–∏ –æ—à–∏–±–∫–µ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        """
        if context and not await RecService._handle_request(context):
            return []
            
        try:
            model, dataset = await ModelManager().get_model()
            recos = model.recommend_to_items(target_items=[item_id], dataset=dataset, k=40, filter_itself=False)
            return recos['item_id'].tolist()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ—Ö–æ–∂–∏—Ö –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–π –¥–ª—è ID {item_id}: {e}")
            if context:
                await context.abort(grpc.StatusCode.INTERNAL, str(e))
            raise

    @staticmethod
    async def train(context: Optional[grpc.ServicerContext] = None) -> bool:
        """
        –ó–∞–ø—É—Å–∫–∞–µ—Ç –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤—Ä—É—á–Ω—É—é.
        
        Args:
            context: gRPC –∫–æ–Ω—Ç–µ–∫—Å—Ç (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            
        Returns:
            bool: –£—Å–ø–µ—à–Ω–æ –ª–∏ –æ–±—É—á–µ–Ω–∏–µ
            
        Raises:
            Exception: –ü—Ä–∏ –æ—à–∏–±–∫–µ –æ–±—É—á–µ–Ω–∏—è
        """
        try:
            result = await ModelManager().train()
            if not result and context:
                await context.abort(grpc.StatusCode.INTERNAL, "–û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏")
            return result
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏: {e}")
            if context:
                await context.abort(grpc.StatusCode.INTERNAL, str(e))
            raise
